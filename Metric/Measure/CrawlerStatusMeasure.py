from Metric.Measure.Measure import Measure
from Database.Database import Database
from Database.ModelFactory.AppModelFactory import AppModelFactory
from datetime import datetime
from sqlalchemy import func, case, select
from sqlalchemy.dialects.postgresql import insert  # é—œéµï¼šå¼•å…¥ PostgreSQL çš„ Insert
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

class CrawlerStatusMeasure(Measure):
    def __init__(self, modelFactory: AppModelFactory, crawlerDB: Database, metricDB: Database):
        super().__init__()
        self.crawlerDB: Database = crawlerDB
        self.metricDB: Database = metricDB
        self.modelFactory: AppModelFactory = modelFactory
    
    def _scan_shard(self, shard_id):
        # é€™è£¡ä½¿ç”¨ crawlerDB çš„ session
        with self.crawlerDB.session() as session:
            try:
                # å‡è¨­ factory ä¹Ÿèƒ½ç”¢ç”Ÿ Shard Model
                UrlState = self.modelFactory.create_url_state_model(shard_id)
                
                stmt = select(
                    func.count(),
                    func.count(case((UrlState.fetch_ok > 0, 1))),
                    func.count(case((UrlState.indexed > 0, 1)))
                )
                
                result = session.execute(stmt).one()
                return shard_id, result[0], result[1], result[2]
                
            except Exception as e:
                # éŒ¯èª¤è™•ç†ï¼šå›å‚³ 0 é¿å…å½±éŸ¿æ•´é«”çµ±è¨ˆ
                return shard_id, 0, 0, 0
    
    def test(self):
        now = datetime.now()
        date_str = now.strftime('%Y-%m-%d')
        
        # 1. åˆå§‹åŒ–çµ±è¨ˆå®¹å™¨
        stats = {
            "total":   {"discovered": 0, "crawled": 0, "indexed": 0},
            "team_a":  {"discovered": 0, "crawled": 0, "indexed": 0},
            "team_b":  {"discovered": 0, "crawled": 0, "indexed": 0}
        }

        print(f'ğŸš€ Start Measuring Status (Parallel) - {date_str}')
        
        # 2. å¹³è¡Œæƒæ Shards
        MAX_WORKERS = 16
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = [executor.submit(self._scan_shard, i) for i in range(256)]
            
            for future in tqdm(as_completed(futures), total=256, desc="Scanning"):
                shard_id, disc, crawl, idx = future.result()
                
                # åˆ†é¡
                if 0 <= shard_id <= 127:
                    team_key = "team_a"
                else:
                    team_key = "team_b"
                
                # ç´¯åŠ 
                for key, val in [("discovered", disc), ("crawled", crawl), ("indexed", idx)]:
                    stats[team_key][key] += val
                    stats["total"][key] += val

        # 3. å¯«å…¥ MetricDB (é—œéµä¿®æ”¹éƒ¨åˆ†)
        print(f"ğŸ’¾ Saving to MetricDB...")
        
        # å®šç¾©æ˜ å°„é—œä¿‚ï¼šstats key -> Factory suffix
        mapping = [
            ("total", "Total"),
            ("team_a", "A"),
            ("team_b", "B")
        ]

        with self.metricDB.session() as session:
            for stats_key, suffix in mapping:
                # A. é€é Factory å–å¾—å°æ‡‰çš„ Class (ä¾‹å¦‚ CrawlerStatA)
                # æ³¨æ„ï¼šé€™è£¡ä¾è³´å…ˆå‰å®šç¾©çš„ AppModelFactory.create_crawler_stat
                ModelClass = self.modelFactory.create_crawler_stat_model(suffix)
                
                # B. æº–å‚™è¦å¯«å…¥çš„è³‡æ–™
                row_data = {
                    "stat_date": date_str,
                    "discovered": stats[stats_key]["discovered"],
                    "crawled":    stats[stats_key]["crawled"],
                    "indexed":    stats[stats_key]["crawled"] # temp
                }
                
                # C. åŸ·è¡Œ Upsert (Insert on Conflict Update)
                # é€™æ¨£åšçš„å¥½è™•æ˜¯ï¼šå¦‚æœè©²æ—¥æœŸçš„ fetch_ok å·²ç¶“è¢«å…¶ä»–ç¨‹å¼å¯«å…¥äº†ï¼Œ
                # é€™æ®µç¨‹å¼ç¢¼åªæœƒã€Œæ›´æ–°ã€ discovered/crawled/indexedï¼Œä¸æœƒè“‹æ‰ fetch_okã€‚
                stmt = insert(ModelClass).values(row_data)
                stmt = stmt.on_conflict_do_update(
                    index_elements=['stat_date'], # ä¾æ“šä¸»éµåˆ¤æ–·è¡çª
                    set_=row_data                 # è¡çªæ™‚æ›´æ–°é€™äº›æ¬„ä½
                )
                
                session.execute(stmt)
            
            # ä¸€æ¬¡æäº¤æ‰€æœ‰è®Šæ›´
            session.commit()

        # 4. è¼¸å‡ºå ±å‘Š
        self._print_report(date_str, stats)

    def _print_report(self, date_str, stats):
        print("\n" + "="*35)
        print(f"ğŸ“Š Crawler Status Report: {date_str}")
        print("="*35)
        # ç°¡å–®çš„å°é½Šæ ¼å¼åŒ–
        headers = f"{'Group':<8} | {'Discovered':>12} | {'Crawled':>12} | {'Indexed':>12}"
        print(headers)
        print("-" * len(headers))
        
        for group in ["team_a", "team_b", "total"]:
            d = stats[group]
            print(f"{group.upper():<8} | {d['discovered']:>12,} | {d['crawled']:>12,} | {d['indexed']:>12,}")
        print("="*35)